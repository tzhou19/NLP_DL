{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e06698ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da08f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "360db6dd",
   "metadata": {},
   "source": [
    "# Layer Norm by hand\n",
    "- Fill in the Layer Norm application below. Make sure the manual and PyTorch implementations are the same.\n",
    "- As before, FILL_IN the missing code to make this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9220f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILL_IN = \"FILL_IN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05d979eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_norm_manual @ 0:  tensor([[ 1.0778,  0.8917, -0.7573, -1.2122],\n",
      "        [ 0.6493, -1.1193, -0.8174,  1.2874],\n",
      "        [ 0.8958, -1.4179, -0.4637,  0.9859]])\n",
      "layer_norm_out[0]:  tensor([[ 1.0778,  0.8917, -0.7573, -1.2122],\n",
      "        [ 0.6493, -1.1193, -0.8174,  1.2874],\n",
      "        [ 0.8958, -1.4179, -0.4637,  0.9859]], grad_fn=<SelectBackward0>)\n",
      "layer_norm_manual @ 1:  tensor([[ 0.1667, -0.8487, -0.8877,  1.5697],\n",
      "        [-0.5175,  1.2202,  0.6476, -1.3504],\n",
      "        [-1.6232, -0.0134,  0.9315,  0.7051]])\n",
      "layer_norm_out[1]:  tensor([[ 0.1667, -0.8487, -0.8877,  1.5697],\n",
      "        [-0.5175,  1.2202,  0.6476, -1.3504],\n",
      "        [-1.6232, -0.0134,  0.9315,  0.7051]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# This is (N, T, d_model)\n",
    "# N: batch size\n",
    "# T: sentence_length\n",
    "# d_model: embedding dimension\n",
    "\n",
    "N, T, d_model = 2, 3, 4\n",
    "\n",
    "# An embedding. This is what you might feed into a network.\n",
    "embedding = torch.randn(N, T, d_model)\n",
    "\n",
    "# Create a Layer Norm layer on the embedding dimension.\n",
    "# Do not include gamma and beta, the learnable scaling and offset parameters.\n",
    "# This should act of the dimenson of the model.\n",
    "layer_norm = nn.LayerNorm(d_model)\n",
    "# Run embedding through the layer_norm layer.\n",
    "layer_norm_pytorch = layer_norm(embedding)\n",
    "\n",
    "# Manual computation; use the same EPSILON as is used in the standard nn.LayerNorm.\n",
    "EPSILON = 1e-5\n",
    "\n",
    "# Grab the mean of each vector in the first batch. This should be (3, 1).\n",
    "mean = torch.mean(embedding[0],dim=1).unsqueeze(1)\n",
    "# Grab the var of each vector in the first batch. This should be (3, 1).\n",
    "var = torch.var(embedding[0],dim=1, unbiased=False).unsqueeze(1)\n",
    "# Manually take each vector in the batch and standerdize it.\n",
    "layer_norm_manual = (embedding[0]-mean)/torch.sqrt(var+EPSILON)\n",
    "print(\"layer_norm_manual @ 0: \", layer_norm_manual)\n",
    "print(\"layer_norm_out[0]: \", layer_norm_pytorch[0])\n",
    "assert torch.allclose(layer_norm_pytorch[0], layer_norm_manual), 'Tensors do not match.'\n",
    "\n",
    "mean = torch.mean(embedding[1],dim=1).unsqueeze(1)\n",
    "var = torch.var(embedding[1],dim=1, unbiased=False).unsqueeze(1)\n",
    "layer_norm_manual = (embedding[1]-mean)/torch.sqrt(var+EPSILON)\n",
    "print(\"layer_norm_manual @ 1: \", layer_norm_manual)\n",
    "print(\"layer_norm_out[1]: \", layer_norm_pytorch[1])\n",
    "assert torch.allclose(layer_norm_pytorch[1], layer_norm_manual), 'Tensors do not match.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b889fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97961f13",
   "metadata": {},
   "source": [
    "### Wave Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7d1778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters we will use.                                                                                                                                                          \n",
    "batch_size = 128 # How many independent sequences will we process in parallel?                                                                                              \n",
    "context_size = 256 # What is the maximum context length for predictions? This is T below.                                                                                                    \n",
    "epochs = 5000\n",
    "eval_interval = 500\n",
    "# Is this a good one? Can you check?\n",
    "learning_rate = 3e-3\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "eval_iters = 200\n",
    "d_model = 20\n",
    "d_hidden = 100\n",
    "n_layer = 1\n",
    "dropout = 0.2\n",
    "write_to_file = False\n",
    "norm = 'batch_norm'\n",
    "\n",
    "# Add more pritning to the model.\n",
    "debug = False\n",
    "# ------------        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6054eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "# Load the Shakespere document input.txt.                                                                          \n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3caf7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique characters in the text.                                                                                                             \n",
    "chars = list(set(text))\n",
    "vocab_size = len(list(set(text)))\n",
    "# As usual, create a mapping from a character to a text.                                                                                                                            \n",
    "stoi = {char:i for i, char in enumerate(chars)}\n",
    "itos = {i:char for i, char in enumerate(chars)}\n",
    "# encode: is a lambda function that takes a string and returns  a list of ints, where each character is mapped to the right int.\n",
    "encode = lambda x:[stoi[e] for e in x]\n",
    "# decode: is the reverse mapping of encode. It takes a list of int, and returns a string.\n",
    "decode = lambda x:''.join(itos[e] for e in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35d31f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a train-test split with 90% of the data train and 10% test.\n",
    "# You can just use the first 90% of the data as training data.\n",
    "# Run the text through the encode method.\n",
    "data = encode(text)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val                                                                                                                 \n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2be655fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "# This should return a small batch of data (x, y) where x is \n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y.\n",
    "    # Pick the train data if split == 'train', else the validation data.\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # Select a random set of ints [0, len(data) - context_size) ; reshape this to be (batch_size, )\n",
    "    # For an index i, a x should be data[i:i+context_size] while a y should be data[i+context_size].\n",
    "    # ix has length batch_size.\n",
    "    ix = torch.randint(0,len(data) - context_size, (batch_size, ))\n",
    "    # Stack the batch_size data to be of shape (batch_size, context_size)\n",
    "    x = torch.tensor([data[i.item():i.item()+context_size] for i in ix])\n",
    "    # Stack the y targets; this should be of length batch_size.\n",
    "    # You should pull out the i+context_size element of data; i is an index in ix.\n",
    "    y = torch.tensor([data[i.item()+context_size] for i in ix])                                                                          \n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce7b32c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the loss.\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    # Put the model in eval mode. Why?\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            xb, yb = get_batch(split)\n",
    "            logits, loss = model(xb, yb)\n",
    "            # Get the value in the loss.\n",
    "            losses[k] = loss.item()\n",
    "        # Get the mean of the values in the losses.\n",
    "        out[split] = losses.mean().item()\n",
    "    # Put the model in train mode.\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e436092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetMLPLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "        self.linear_layers = []\n",
    "        self.norm_layers = []\n",
    "        self.linear_layers_res = []\n",
    "\n",
    "        temp_context_size = context_size\n",
    "        \n",
    "        while temp_context_size >= 10:\n",
    "            # Map from 2 * d_model to d_hidden.\n",
    "            if not self.linear_layers:\n",
    "                # Add to linear_layers a layer going 2 * d_model to d_hidden.\n",
    "                self.linear_layers.append(nn.Linear(2*d_model, d_hidden))\n",
    "                self.linear_layers_res.append(nn.Linear(2*d_model, d_hidden))\n",
    "            else:\n",
    "                # Map from 2 * d_hidden to d_hidden.\n",
    "                # Add to linear_layers a layer going 2 * d_hidden to d_hidden.\n",
    "                self.linear_layers.append(nn.Linear(2*d_hidden, d_hidden))\n",
    "                self.linear_layers_res.append(nn.Linear(2*d_hidden, d_hidden))\n",
    "            # Append to norm_layers a batch norm 1d with vectors of size d_hidden.\n",
    "            self.norm_layers.append(nn.BatchNorm1d(d_hidden))\n",
    "            \n",
    "            temp_context_size //= 2\n",
    "        \n",
    "        # Add a final batch norm 1d with vectors of size vocab_size. \n",
    "        self.norm_f = nn.BatchNorm1d(vocab_size) # Final layer norm.\n",
    "        # Add a Linear layer going from temp_context_size * d_hidden to vocab_size.\n",
    "        self.ff = nn.Linear(temp_context_size * d_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        N, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (N, T) tensor of integers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "        x = self.token_embedding_table(idx) # (N, T, d_model)\n",
    "        \n",
    "        for i, _ in enumerate(self.linear_layers):\n",
    "            N, T, D = x.shape\n",
    "            # Reshape x to be (N, ??). You want to shrink the context window down by two each time.\n",
    "            x = x.reshape(N, T//2, D * 2)\n",
    "            # Residual Connection\n",
    "            # residual = x    \n",
    "            # Pass through linear layer i.\n",
    "            x_res = self.linear_layers_res[i](x)\n",
    "            x = self.linear_layers[i](x)\n",
    "            # Transpose appropriate dimensions of x. Look at the expected dimensions of BatchNorm1d.\n",
    "            x = x.transpose(1,2)\n",
    "            # Pass through the batch norm layer.\n",
    "            x = self.norm_layers[i](x)\n",
    "            # Transpose back to the previous dimensions.\n",
    "            x = x.transpose(1,2)\n",
    "            # Pass through ReLU.\n",
    "            # x = x.relu()\n",
    "            # Residual Connection\n",
    "\n",
    "            x = x.relu() + x_res\n",
    "        \n",
    "        # Reshape.\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "            # (N, [T // (2 ** len(self.linear_layers))] * d_model)\n",
    "        \n",
    "        # Apply dropout.\n",
    "        dp =  nn.Dropout(p=dropout)\n",
    "        x = dp(x)\n",
    "        \n",
    "        # Apply self.ff.\n",
    "        x = self.ff(x) # (N, vocab_size)\n",
    "        \n",
    "        # Apply batch norm.\n",
    "        x = self.norm_f(x)\n",
    "\n",
    "        # Apply Tanh.\n",
    "        logits = x\n",
    "        # logits = x.tanh()\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            _, T = logits.shape\n",
    "\n",
    "            assert(T == vocab_size)\n",
    "\n",
    "            # Apply cross entropy.\n",
    "            loss = nn.functional.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is a (N, T) array of indices in the current context.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "        for _ in range(max_new_tokens):\n",
    "            # Here, we crop idx to the last context_size tokens.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "            idx_cond = idx[:, -context_size:]\n",
    "            # Get the predictions; this is just the last timestep.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "            logits, loss = self.forward(idx_cond)\n",
    "            # Apply softmax to get probabilities.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "            probs = nn.functional.softmax(logits) # (N, vocab_size)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            # Sample from the distribution to get the next character's index.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "            idx_next = torch.multinomial(probs, 1) # (N, 1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "            # Append sampled index to the running sequence.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "            idx = torch.cat((idx, idx_next), 1) # (N, T+1)\n",
    "        return idx # At most, this is (N, T + max_new_tokens) in the second dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83698536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetMLPLanguageModel_layernorm(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "        self.linear_layers = []\n",
    "        self.norm_layers = []\n",
    "        self.linear_layers_res = []\n",
    "\n",
    "        temp_context_size = context_size\n",
    "        \n",
    "        while temp_context_size >= 10:\n",
    "            # Map from 2 * d_model to d_hidden.\n",
    "            if not self.linear_layers:\n",
    "                # Add to linear_layers a layer going 2 * d_model to d_hidden.\n",
    "                self.linear_layers.append(nn.Linear(2*d_model, d_hidden))\n",
    "                self.linear_layers_res.append(nn.Linear(2*d_model, d_hidden))\n",
    "            else:\n",
    "                # Map from 2 * d_hidden to d_hidden.\n",
    "                # Add to linear_layers a layer going 2 * d_hidden to d_hidden.\n",
    "                self.linear_layers.append(nn.Linear(2*d_hidden, d_hidden))\n",
    "                self.linear_layers_res.append(nn.Linear(2*d_hidden, d_hidden))\n",
    "            # Append to norm_layers a batch norm 1d with vectors of size d_hidden.\n",
    "            self.norm_layers.append(nn.LayerNorm([d_hidden,temp_context_size//2]))\n",
    "            \n",
    "            temp_context_size //= 2\n",
    "        \n",
    "        # Add a final batch norm 1d with vectors of size vocab_size. \n",
    "        self.norm_f = nn.LayerNorm(vocab_size) # Final layer norm.\n",
    "        # Add a Linear layer going from temp_context_size * d_hidden to vocab_size.\n",
    "        self.ff = nn.Linear(temp_context_size * d_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        N, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (N, T) tensor of integers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "        x = self.token_embedding_table(idx) # (N, T, d_model)\n",
    "        \n",
    "        for i, _ in enumerate(self.linear_layers):\n",
    "            N, T, D = x.shape\n",
    "            # Reshape x to be (N, ??). You want to shrink the context window down by two each time.\n",
    "            x = x.reshape(N, T//2, D * 2)\n",
    "            # Residual Connection\n",
    "            # residual = x    \n",
    "            # Pass through linear layer i.\n",
    "            x_res = self.linear_layers_res[i](x)\n",
    "            x = self.linear_layers[i](x)\n",
    "            # Transpose appropriate dimensions of x. Look at the expected dimensions of BatchNorm1d.\n",
    "            x = x.transpose(1,2)\n",
    "            # Pass through the batch norm layer.\n",
    "            x = self.norm_layers[i](x)\n",
    "            # Transpose back to the previous dimensions.\n",
    "            x = x.transpose(1,2)\n",
    "            # Pass through ReLU.\n",
    "            # x = x.relu()\n",
    "            # Residual Connection\n",
    "\n",
    "            x = x.relu() + x_res\n",
    "        \n",
    "        # Reshape.\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "            # (N, [T // (2 ** len(self.linear_layers))] * d_model)\n",
    "        \n",
    "        # Apply dropout.\n",
    "        dp =  nn.Dropout(p=dropout)\n",
    "        x = dp(x)\n",
    "        \n",
    "        # Apply self.ff.\n",
    "        x = self.ff(x) # (N, vocab_size)\n",
    "        \n",
    "        # Apply batch norm.\n",
    "        x = self.norm_f(x)\n",
    "\n",
    "        # Apply Tanh.\n",
    "        logits = x\n",
    "        # logits = x.tanh()\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            _, T = logits.shape\n",
    "\n",
    "            assert(T == vocab_size)\n",
    "\n",
    "            # Apply cross entropy.\n",
    "            loss = nn.functional.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is a (N, T) array of indices in the current context.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "        for _ in range(max_new_tokens):\n",
    "            # Here, we crop idx to the last context_size tokens.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "            idx_cond = idx[:, -context_size:]\n",
    "            # Get the predictions; this is just the last timestep.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "            logits, loss = self.forward(idx_cond)\n",
    "            # Apply softmax to get probabilities.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "            probs = nn.functional.softmax(logits) # (N, vocab_size)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            # Sample from the distribution to get the next character's index.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "            idx_next = torch.multinomial(probs, 1) # (N, 1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "            # Append sampled index to the running sequence.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "            idx = torch.cat((idx, idx_next), 1) # (N, T+1)\n",
    "        return idx # At most, this is (N, T + max_new_tokens) in the second dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eeeab8",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25752635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53495 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = WaveNetMLPLanguageModel_layernorm().to(device)\n",
    "# Print the number of parameters in the model.\n",
    "print(sum(p.numel() for p in model.parameters()) , 'M parameters')\n",
    "\n",
    "# Create a PyTorch optimizer. Use AdamW.                                                                                                                                                                                                                                        \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ca598bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero gradient parameters:  5\n",
      "step 0: train loss 4.6147, val loss 4.6110\n",
      "Number of zero gradient parameters:  0\n",
      "step 500: train loss 3.2912, val loss 3.3390\n",
      "Number of zero gradient parameters:  0\n",
      "step 1000: train loss 3.1802, val loss 3.2259\n",
      "Number of zero gradient parameters:  0\n",
      "step 1500: train loss 3.0848, val loss 3.1041\n",
      "Number of zero gradient parameters:  0\n",
      "step 2000: train loss 3.0058, val loss 3.0174\n",
      "Number of zero gradient parameters:  0\n",
      "step 2500: train loss 2.9363, val loss 2.9706\n",
      "Number of zero gradient parameters:  0\n",
      "step 3000: train loss 2.9224, val loss 2.9428\n",
      "Number of zero gradient parameters:  0\n",
      "step 3500: train loss 2.8936, val loss 2.9293\n",
      "Number of zero gradient parameters:  0\n",
      "step 4000: train loss 2.8614, val loss 2.9139\n",
      "Number of zero gradient parameters:  0\n",
      "step 4500: train loss 2.8650, val loss 2.9046\n",
      "Number of zero gradient parameters:  0\n",
      "step 4999: train loss 2.8416, val loss 2.8966\n"
     ]
    }
   ],
   "source": [
    "# Here we loop over max_iters and at each iter we get a batch of data we optimize over.\n",
    "model.train()\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets                                                                                                                                                                                                 \n",
    "    if epoch % eval_interval == 0 or epoch == epochs - 1:\n",
    "        losses = estimate_loss()\n",
    "        train_loss.append(losses['train'])\n",
    "        validation_loss.append(losses['val'])\n",
    "        print('Number of zero gradient parameters: ', sum(p.grad is None for p in model.parameters()))\n",
    "        print(f\"step {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # Sample a batch of data                                                                                                                                                                                                                                        \n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss                                                                                                                                                                                                                                             \n",
    "    logits, loss = model(xb, yb)\n",
    "    # Zero the grads.\n",
    "    optimizer.zero_grad()\n",
    "    # Get gradients by backprop; do a parameter update.\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f107b0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(0,len(train_loss)*500,500), train_loss, label='train')\n",
    "plt.plot(range(0,len(train_loss)*500,500), validation_loss, label='validation')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae0653ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_29580\\696807408.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = nn.functional.softmax(logits) # (N, vocab_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "IMt siieirr, Ais iu je oe.\n",
      "\n",
      "yTINIabug h rnetre grovhe\n",
      "Se,\n",
      "thfaI Toadc ruo reFmi,rtmthr me fhuthnikyac eootyie'r oome tenddam sute ui, Jabfh dsowsaia  yeos lgs  bmtu niced ffto e'rax co,euaav noss cam meauutartka, f peonnvedss ramir- a s,easwmeyssy ihe? th hhacinspsairr gece daf e An fe: rutimserH an,mi o nosftinth -hlesaat sronbl omoas chho hms.\n",
      "\n",
      "I\n",
      "'pL ICgNs shf  bi riy beatnarf ss wohP  tids wepsb g  worif worsa thea miss n: he\n",
      "\n",
      "ThoI kilMesyobap s twweon neti chodrem-td  ln ohi,iu fef reohi r  \n"
     ]
    }
   ],
   "source": [
    "# Generate from the model and save it to wave_net.txt.\n",
    "# We generate a maximum of 1000 tokens. \n",
    "# We feed in a batch of dimenson (1, context_size).\n",
    "# The loss should get to ~ 2.0 on train and validation.\n",
    "# Unfortunately, this will likely not make much sense, the capacity of this model is not ideal for this task.\n",
    "# The name generation task fro HW 1 might be aother data set to use.\n",
    "model.eval()\n",
    "context = torch.tensor(train_data[:256]).reshape(1, 256)\n",
    "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "if write_to_file:\n",
    "    open('wave_net.txt', 'w').write(decode(model.generate(context, max_new_tokens=10000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c2f21",
   "metadata": {},
   "source": [
    "Bonus (+5 max - If you do this and it's all right this assignment will be 13/10.)\n",
    "- Add some residual connections. Does this improve gradient zero issues?\n",
    " - Add some logging to figure out the number of zero gradients across the network before and after you add the residual connections.\n",
    "- Add some plots that show the train and validation loss, per k iterations. You might want k < 500.\n",
    "- Use LayerNorm instead of batch norm.\n",
    "- Use the names.txt file from assignment 1. How do the names look?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b7c0c18",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "39b32084",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "33cf5361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique characters in the text.                                                                                                             \n",
    "chars = list(set(text))\n",
    "vocab_size = len(list(set(text)))\n",
    "# As usual, create a mapping from a character to a text.                                                                                                                            \n",
    "stoi = {char:i for i, char in enumerate(chars)}\n",
    "itos = {i:char for i, char in enumerate(chars)}\n",
    "# encode: is a lambda function that takes a string and returns  a list of ints, where each character is mapped to the right int.\n",
    "encode = lambda x:[stoi[e] for e in x]\n",
    "# decode: is the reverse mapping of encode. It takes a list of int, and returns a string.\n",
    "decode = lambda x:''.join(itos[e] for e in x)\n",
    "\n",
    "data = encode(text)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val                                                                                                                 \n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7df9cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22221 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = WaveNetMLPLanguageModel_layernorm().to(device)\n",
    "# Print the number of parameters in the model.\n",
    "print(sum(p.numel() for p in model.parameters()) , 'M parameters')\n",
    "\n",
    "# Create a PyTorch optimizer. Use AdamW.                                                                                                                                                                                                                                        \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5bde783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero gradient parameters:  5\n",
      "step 0: train loss 3.7160, val loss 3.7075\n",
      "Number of zero gradient parameters:  0\n",
      "step 500: train loss 2.7494, val loss 2.8597\n",
      "Number of zero gradient parameters:  0\n",
      "step 1000: train loss 2.6576, val loss 2.7701\n",
      "Number of zero gradient parameters:  0\n",
      "step 1500: train loss 2.6117, val loss 2.7346\n",
      "Number of zero gradient parameters:  0\n",
      "step 2000: train loss 2.5560, val loss 2.6908\n",
      "Number of zero gradient parameters:  0\n",
      "step 2500: train loss 2.5500, val loss 2.6729\n",
      "Number of zero gradient parameters:  0\n",
      "step 3000: train loss 2.5309, val loss 2.6411\n",
      "Number of zero gradient parameters:  0\n",
      "step 3500: train loss 2.5133, val loss 2.6251\n",
      "Number of zero gradient parameters:  0\n",
      "step 4000: train loss 2.5042, val loss 2.6278\n",
      "Number of zero gradient parameters:  0\n",
      "step 4500: train loss 2.5028, val loss 2.6335\n",
      "Number of zero gradient parameters:  0\n",
      "step 4999: train loss 2.4957, val loss 2.5982\n"
     ]
    }
   ],
   "source": [
    "# Here we loop over max_iters and at each iter we get a batch of data we optimize over.\n",
    "model.train()\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets                                                                                                                                                                                                 \n",
    "    if epoch % eval_interval == 0 or epoch == epochs - 1:\n",
    "        losses = estimate_loss()\n",
    "        train_loss.append(losses['train'])\n",
    "        validation_loss.append(losses['val'])\n",
    "        print('Number of zero gradient parameters: ', sum(p.grad is None for p in model.parameters()))\n",
    "        print(f\"step {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # Sample a batch of data                                                                                                                                                                                                                                        \n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss                                                                                                                                                                                                                                             \n",
    "    logits, loss = model(xb, yb)\n",
    "    # Zero the grads.\n",
    "    optimizer.zero_grad()\n",
    "    # Get gradients by backprop; do a parameter update.\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "766e6f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0,len(train_loss)*500,500), train_loss, label='train')\n",
    "plt.plot(range(0,len(train_loss)*500,500), validation_loss, label='validation')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7fb11c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_29580\\696807408.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = nn.functional.softmax(logits) # (N, vocab_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "olivia\n",
      "ava\n",
      "isabella\n",
      "sophia\n",
      "charlotte\n",
      "mia\n",
      "amelia\n",
      "harper\n",
      "evelyn\n",
      "abigail\n",
      "emily\n",
      "elizabeth\n",
      "mila\n",
      "ella\n",
      "avery\n",
      "sofia\n",
      "camila\n",
      "aria\n",
      "scarlett\n",
      "victoria\n",
      "madison\n",
      "luna\n",
      "grace\n",
      "chloe\n",
      "penelope\n",
      "layla\n",
      "riley\n",
      "zoey\n",
      "nora\n",
      "lily\n",
      "eleanor\n",
      "hannah\n",
      "lillian\n",
      "addison\n",
      "aubrey\n",
      "ellie\n",
      "stella\n",
      "nileabab\n",
      "yaalinawee\n",
      "kidhyleidyre\n",
      "maeaal\n",
      "riwhasnia\n",
      "kmazienmeavolvabelana\n",
      "brisanve\n",
      "oaatga\n",
      "bkiviyc\n",
      "eloa\n",
      "riiar\n",
      "bsnhlana\n",
      "eiasy\n",
      "retell\n",
      "lnoo\n",
      "mralyeaagidhae\n",
      "eenn\n",
      "arnhet\n",
      "mmsia\n",
      "lh\n",
      "hualtby\n",
      "atiae\n",
      "kaaatrlzacelh\n",
      "ccia\n",
      "tiykas\n",
      "aeninn\n",
      "coklelmoye\n",
      "oinaenan\n",
      "bhyi\n",
      "xatvih\n",
      "raiil\n",
      "jhyzaya\n",
      "zeecxai\n",
      "ehmarlhe\n",
      "masaytt\n",
      "heblalocuyk\n",
      "itzayn\n",
      "amaaea\n",
      "dinannhn\n",
      "vilaw\n",
      "nn\n",
      "tlineana\n",
      "oyneh\n",
      "jiholanwnia\n",
      "iarn\n",
      "ceaas\n",
      "lhw\n",
      "iidato\n",
      "dhyeclenene\n",
      "saiato\n",
      "nrhel\n",
      "nyrih\n",
      "aaami\n",
      "\n",
      "nirdanrs\n",
      "amahselloeevan\n",
      "aanc\n",
      "lyayenna\n",
      "sar\n",
      "yri\n",
      "ramiaawor\n",
      "niil\n",
      "\n",
      "selgn\n",
      "cnnia\n",
      "ealytanv\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "context = torch.tensor(train_data[:256]).reshape(1, 256)\n",
    "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadb5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9f4c2e3c7edcc74941d763c22ae9bb8d5716b7961b59c0906229ce5f7f5dcfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
