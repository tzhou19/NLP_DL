{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db00378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.data.utils import get_tokenizer, ngrams_iterator\n",
    "from torchtext.datasets import DATASETS\n",
    "from torchtext.prototype.transforms import load_sp_model, PRETRAINED_SP_MODEL, SentencePieceTokenizer\n",
    "from torchtext.utils import download_from_url\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df7f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcb35e9c",
   "metadata": {},
   "source": [
    "### Information\n",
    "- torchtext repo: https://github.com/pytorch/text/tree/main/torchtext\n",
    "- torchtext documentation: https://pytorch.org/text/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4d6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9140e3c",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ace94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"WikiText2\"\n",
    "DATA_DIR = \".data\"\n",
    "DEVICE = \"cpu\"\n",
    "LR = 4.0\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 5\n",
    "MIN_FREQUENCY = 5\n",
    "PADDING_VALUE = 0\n",
    "PADDING_IDX = PADDING_VALUE\n",
    "\n",
    "# n-gram level\n",
    "n = 3\n",
    "# Hidden layer dimension\n",
    "h = 100\n",
    "# Word embedding dimension\n",
    "m = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff816ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09f16039",
   "metadata": {},
   "source": [
    "### Get the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f471ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_english_tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b61bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'some', 'text', '.', '.', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_english_tokenizer(\"This is some text ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a50055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed later.\n",
    "TOKENIZER = basic_english_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620a436",
   "metadata": {},
   "source": [
    "### Get the data and get the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c84225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield TOKENIZER(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affa3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DATASETS[DATASET](root=DATA_DIR, split=\"train\")\n",
    "VOCAB = build_vocab_from_iterator(yield_tokens(train_iter), min_freq = MIN_FREQUENCY, specials=['<unk>'])\n",
    "\n",
    "# Set the default index to 1. Otherwise, VOCAB['unknownbigword'] will raise an Exception.\n",
    "VOCAB.set_default_index(VOCAB['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62336be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "518918c0",
   "metadata": {},
   "source": [
    "Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de48bde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 324, 0, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB['yoyooyoyoy'], VOCAB['house'], VOCAB['<pad>'], VOCAB['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24247d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20409\n"
     ]
    }
   ],
   "source": [
    "print(len(VOCAB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574cce1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[324, 324, 1374, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.lookup_indices(TOKENIZER(\"House house houses ThisisnotaKNownWord\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1e272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df651a44",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94741f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x):\n",
    "    return VOCAB(TOKENIZER(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e903610",
   "metadata": {},
   "source": [
    "Nice link on collate_fn and DataLoader in PyTorch: https://python.plainenglish.io/understanding-collate-fn-in-pytorch-f9d1742647d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95311731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    source_list, target_list = [], []\n",
    "        \n",
    "    for sentence in batch:\n",
    "                        \n",
    "        tokens = text_pipeline(sentence)\n",
    "        \n",
    "        for i in range(len(tokens)):\n",
    "            if i + n -1 <= len(tokens) - 1:\n",
    "                source, target = tokens[i:i+n-1], tokens[i+n-1]\n",
    "                source_list.append(torch.tensor(source))\n",
    "                target_list.append(torch.tensor(target))\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    source_list = torch.vstack(source_list) if source_list else torch.empty()\n",
    "    target_list = torch.vstack(target_list) if target_list else torch.empty()\n",
    "            \n",
    "    return source_list.to(DEVICE), target_list.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1292c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eca51b36",
   "metadata": {},
   "source": [
    "### Set up the model\n",
    "- nn.Embedding(V, D) is like a hash map.\n",
    "- It takes in data generally of the shape N X T where N is the batch size and returns a tensor of shape N X T X D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b4f143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "# Data is of size 16 by 10 with a vocabulary of size 10.\n",
    "# Imagine that each token / word has a mapping of the sort {word -> id}.\n",
    "x = torch.randint(0, 10, (16, 10))\n",
    "e = nn.Embedding(10, 5)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1fb50a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5461,  1.8204,  1.9322, -0.9027,  1.2370],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e(torch.tensor(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc2bd673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(3), num_classes=10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc52d408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5461,  1.8204,  1.9322, -0.9027,  1.2370],\n",
       "       grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(3), num_classes=10).float() @ e.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c0fa6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "e = nn.Embedding(10, 5)\n",
    "# N X T X D - PyTorch is smart enough to realize you are passing in a batch.\n",
    "print(e(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8612ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ab8cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the first Neural language models!\n",
    "class NeuralLanguageModel(nn.Module):\n",
    "    def __init__(self, V, m, h, n):\n",
    "        super(NeuralLanguageModel, self).__init__()\n",
    "        \n",
    "        # Vocabulary size.\n",
    "        self.V = V\n",
    "        \n",
    "        # Embedding dimension, per word.\n",
    "        self.m = m\n",
    "        \n",
    "        # Hidden dimension.\n",
    "        self.h = h\n",
    "        \n",
    "        # n in \"n-gram\".\n",
    "        self.n = n\n",
    "        \n",
    "        # Can you change all this stuff to use nn.Linear?\n",
    "        # Can also use nn.Parameter(torch.zeros(V, m)) for self.C but then we need one-hot and this is slow.\n",
    "        self.C = nn.Embedding(V, m)\n",
    "        \n",
    "        # nn.Linear((n-1) * m, h, bias=False) would give the same thing for the first one below, and similarly later. \n",
    "        self.H = nn.Parameter(torch.zeros((n-1) * m, h))\n",
    "        self.W = nn.Parameter(torch.zeros((n-1) * m, V))\n",
    "        self.U = nn.Parameter(torch.zeros(h, V))\n",
    "        \n",
    "        self.b = torch.nn.Parameter(torch.ones(V))\n",
    "        self.d = torch.nn.Parameter(torch.ones(h))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x is initially of dimension N X n-1 since batch is size N and context is of size n-1.\n",
    "        \n",
    "        # N X (n-1) X m \n",
    "        x = self.C(x)\n",
    "        \n",
    "        # N\n",
    "        B = x.shape[0]\n",
    "        \n",
    "        # N X (n-1) * m\n",
    "        x = x.view(B, -1)\n",
    "    \n",
    "        # N X V\n",
    "        y = self.b + torch.matmul(x, self.W) + torch.matmul(nn.Tanh()(self.d + torch.matmul(x, self.H)), self.U)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d569e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "899045e6",
   "metadata": {},
   "source": [
    "### Set up the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02b8e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "model = NeuralLanguageModel(len(VOCAB), m, h, n).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10508c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8994ae19",
   "metadata": {},
   "source": [
    "### Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eaaa82a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DATASETS[DATASET](root=DATA_DIR, split=\"train\")\n",
    "test_iter = DATASETS[DATASET](root=DATA_DIR, split=\"test\")\n",
    "\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5af374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72b5bb91",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d58cc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_batches = 0.0, 0.0\n",
    "    log_interval = 100\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if x.nelement() == 0:\n",
    "            continue\n",
    "        \n",
    "        logits = model(x)\n",
    "                        \n",
    "        # Get the loss.\n",
    "        loss = criterion(input=logits, target=y.squeeze(-1))\n",
    "\n",
    "        # Do back propagation.\n",
    "        loss.backward()\n",
    "                        \n",
    "        # Clip the gradients.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        \n",
    "        # Do an optimization step.\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_batches += 1\n",
    "                \n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            perplexity = torch.exp(torch.tensor(total_loss / total_batches)).item()\n",
    "            print(\n",
    "                \"| epoch {:3d} \"\n",
    "                \"| {:5d}/{:5d} batches \"\n",
    "                \"| perplexity {:8.3f} \"\n",
    "                \"| loss {:8.3f} \"\n",
    "                .format(\n",
    "                    epoch,\n",
    "                    idx,\n",
    "                    len(dataloader),\n",
    "                    perplexity,\n",
    "                    total_loss / total_batches,\n",
    "                )\n",
    "            )\n",
    "            total_loss, total_batches = 0.0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85722617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_batches = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y) in enumerate(dataloader):\n",
    "            logits = model(x)\n",
    "            total_loss += criterion(input=logits, target=y.squeeze(-1)).item()\n",
    "            total_batches += 1\n",
    "    return total_loss / total_batches, torch.exp(torch.tensor(total_loss / total_batches)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21ba24f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:09, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/ 2181 batches | perplexity 1365.428 | loss    7.219 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:18, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2181 batches | perplexity  794.575 | loss    6.678 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [00:27, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   300/ 2181 batches | perplexity  704.609 | loss    6.558 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [00:36, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   400/ 2181 batches | perplexity  650.531 | loss    6.478 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [00:45, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 2181 batches | perplexity  638.687 | loss    6.459 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [00:54, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   600/ 2181 batches | perplexity  602.584 | loss    6.401 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702it [01:03, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   700/ 2181 batches | perplexity  577.165 | loss    6.358 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "802it [01:12, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   800/ 2181 batches | perplexity  576.052 | loss    6.356 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "902it [01:21, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   900/ 2181 batches | perplexity  545.978 | loss    6.303 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [01:30, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1000/ 2181 batches | perplexity  535.847 | loss    6.284 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1103it [01:40, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1100/ 2181 batches | perplexity  515.846 | loss    6.246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1203it [01:49, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1200/ 2181 batches | perplexity  508.998 | loss    6.232 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1303it [01:58, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1300/ 2181 batches | perplexity  502.147 | loss    6.219 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1402it [02:07, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1400/ 2181 batches | perplexity  494.248 | loss    6.203 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [02:16, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1500/ 2181 batches | perplexity  486.483 | loss    6.187 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1601it [02:25, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1600/ 2181 batches | perplexity  485.920 | loss    6.186 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1703it [02:35, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1700/ 2181 batches | perplexity  470.801 | loss    6.154 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1803it [02:44, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1800/ 2181 batches | perplexity  483.488 | loss    6.181 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1903it [02:53, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1900/ 2181 batches | perplexity  469.686 | loss    6.152 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2003it [03:02, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2000/ 2181 batches | perplexity  460.695 | loss    6.133 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2103it [03:11, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2100/ 2181 batches | perplexity  467.174 | loss    6.147 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2181it [03:18, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 203.71s | valid perplexity  442.561 | valid loss    6.093\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:09, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   100/ 2181 batches | perplexity  426.712 | loss    6.056 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:18, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   200/ 2181 batches | perplexity  420.002 | loss    6.040 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [00:27, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   300/ 2181 batches | perplexity  409.003 | loss    6.014 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "403it [00:37, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   400/ 2181 batches | perplexity  423.491 | loss    6.049 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [00:45, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   500/ 2181 batches | perplexity  420.679 | loss    6.042 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [00:55, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   600/ 2181 batches | perplexity  406.218 | loss    6.007 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "703it [01:04, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   700/ 2181 batches | perplexity  414.638 | loss    6.027 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "803it [01:13, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   800/ 2181 batches | perplexity  407.929 | loss    6.011 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [01:21, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   900/ 2181 batches | perplexity  418.753 | loss    6.037 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1003it [01:31, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1000/ 2181 batches | perplexity  405.121 | loss    6.004 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [01:39, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1100/ 2181 batches | perplexity  411.895 | loss    6.021 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1203it [01:48, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1200/ 2181 batches | perplexity  398.239 | loss    5.987 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1302it [01:57, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1300/ 2181 batches | perplexity  404.945 | loss    6.004 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1402it [02:06, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1400/ 2181 batches | perplexity  393.797 | loss    5.976 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1502it [02:15, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1500/ 2181 batches | perplexity  400.669 | loss    5.993 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1602it [02:24, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1600/ 2181 batches | perplexity  396.139 | loss    5.982 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1702it [02:33, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1700/ 2181 batches | perplexity  400.684 | loss    5.993 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1803it [02:41, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1800/ 2181 batches | perplexity  405.022 | loss    6.004 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1903it [02:50, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1900/ 2181 batches | perplexity  405.906 | loss    6.006 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [02:59, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  2000/ 2181 batches | perplexity  409.754 | loss    6.016 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2101it [03:08, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  2100/ 2181 batches | perplexity  416.871 | loss    6.033 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2181it [03:16, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 201.49s | valid perplexity  420.796 | valid loss    6.042\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:09, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   100/ 2181 batches | perplexity  402.813 | loss    5.998 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:18, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   200/ 2181 batches | perplexity  394.382 | loss    5.977 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "303it [00:27, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   300/ 2181 batches | perplexity  395.010 | loss    5.979 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "402it [00:35, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   400/ 2181 batches | perplexity  396.058 | loss    5.982 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [00:45, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   500/ 2181 batches | perplexity  397.539 | loss    5.985 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [00:53, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   600/ 2181 batches | perplexity  412.807 | loss    6.023 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702it [01:02,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   700/ 2181 batches | perplexity  404.454 | loss    6.003 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "802it [01:12, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   800/ 2181 batches | perplexity  396.707 | loss    5.983 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "903it [01:20, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   900/ 2181 batches | perplexity  381.668 | loss    5.945 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [01:29, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1000/ 2181 batches | perplexity  397.677 | loss    5.986 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [01:39, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1100/ 2181 batches | perplexity  408.783 | loss    6.013 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1203it [01:48, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1200/ 2181 batches | perplexity  400.779 | loss    5.993 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1303it [01:57, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1300/ 2181 batches | perplexity  391.132 | loss    5.969 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [02:06, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1400/ 2181 batches | perplexity  392.799 | loss    5.973 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1503it [02:15, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1500/ 2181 batches | perplexity  400.072 | loss    5.992 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1602it [02:23, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1600/ 2181 batches | perplexity  382.328 | loss    5.946 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1703it [02:32, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1700/ 2181 batches | perplexity  390.291 | loss    5.967 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1803it [02:41, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1800/ 2181 batches | perplexity  394.585 | loss    5.978 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1903it [02:50, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1900/ 2181 batches | perplexity  399.844 | loss    5.991 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2003it [03:00, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  2000/ 2181 batches | perplexity  401.474 | loss    5.995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2103it [03:08, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  2100/ 2181 batches | perplexity  407.191 | loss    6.009 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2181it [03:15, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 201.10s | valid perplexity  422.795 | valid loss    6.047\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:09, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   100/ 2181 batches | perplexity  393.323 | loss    5.975 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:17, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   200/ 2181 batches | perplexity  401.214 | loss    5.994 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [00:26, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   300/ 2181 batches | perplexity  395.319 | loss    5.980 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "402it [00:35, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   400/ 2181 batches | perplexity  400.347 | loss    5.992 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [00:44, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   500/ 2181 batches | perplexity  394.169 | loss    5.977 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [00:53, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   600/ 2181 batches | perplexity  403.042 | loss    5.999 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702it [01:02, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   700/ 2181 batches | perplexity  399.369 | loss    5.990 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "802it [01:12, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   800/ 2181 batches | perplexity  408.989 | loss    6.014 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "903it [01:21, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   900/ 2181 batches | perplexity  397.037 | loss    5.984 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1002it [01:30, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1000/ 2181 batches | perplexity  394.899 | loss    5.979 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1102it [01:39, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1100/ 2181 batches | perplexity  395.815 | loss    5.981 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1202it [01:48, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1200/ 2181 batches | perplexity  405.774 | loss    6.006 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1302it [01:57, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1300/ 2181 batches | perplexity  393.779 | loss    5.976 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1402it [02:06, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1400/ 2181 batches | perplexity  392.671 | loss    5.973 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1502it [02:15, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1500/ 2181 batches | perplexity  392.457 | loss    5.972 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1602it [02:23, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1600/ 2181 batches | perplexity  402.151 | loss    5.997 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1702it [02:33, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1700/ 2181 batches | perplexity  399.806 | loss    5.991 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1803it [02:42, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1800/ 2181 batches | perplexity  395.556 | loss    5.980 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1903it [02:51, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1900/ 2181 batches | perplexity  385.216 | loss    5.954 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2003it [03:00, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  2000/ 2181 batches | perplexity  400.019 | loss    5.992 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2102it [03:09, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  2100/ 2181 batches | perplexity  403.803 | loss    6.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2181it [03:16, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 201.38s | valid perplexity  422.817 | valid loss    6.047\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:09,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   100/ 2181 batches | perplexity  393.077 | loss    5.974 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:18, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   200/ 2181 batches | perplexity  385.955 | loss    5.956 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "303it [00:27, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   300/ 2181 batches | perplexity  395.348 | loss    5.980 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [00:35, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   400/ 2181 batches | perplexity  388.531 | loss    5.962 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [00:45, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   500/ 2181 batches | perplexity  404.721 | loss    6.003 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [00:54, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   600/ 2181 batches | perplexity  409.123 | loss    6.014 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "703it [01:03, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   700/ 2181 batches | perplexity  404.302 | loss    6.002 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "803it [01:12, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   800/ 2181 batches | perplexity  404.142 | loss    6.002 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "903it [01:21, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   900/ 2181 batches | perplexity  407.473 | loss    6.010 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1003it [01:30, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1000/ 2181 batches | perplexity  397.454 | loss    5.985 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1102it [01:39, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1100/ 2181 batches | perplexity  403.600 | loss    6.000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1203it [01:48, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1200/ 2181 batches | perplexity  392.160 | loss    5.972 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1303it [01:57, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1300/ 2181 batches | perplexity  400.891 | loss    5.994 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1403it [02:06, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1400/ 2181 batches | perplexity  392.386 | loss    5.972 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [02:15, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1500/ 2181 batches | perplexity  401.224 | loss    5.995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1603it [02:24, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1600/ 2181 batches | perplexity  398.353 | loss    5.987 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1703it [02:33, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1700/ 2181 batches | perplexity  396.567 | loss    5.983 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1801it [02:42, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1800/ 2181 batches | perplexity  393.961 | loss    5.976 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1903it [02:51, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1900/ 2181 batches | perplexity  402.520 | loss    5.998 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2002it [03:00, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  2000/ 2181 batches | perplexity  390.331 | loss    5.967 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2102it [03:08, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  2100/ 2181 batches | perplexity  385.240 | loss    5.954 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2181it [03:16, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 201.36s | valid perplexity  420.861 | valid loss    6.042\n",
      "-----------------------------------------------------------\n",
      "Checking the results of test dataset.\n",
      "test perplexity  338.582 | test loss    5.825 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader, model, optimizer, criterion, epoch)\n",
    "    loss_val, perplexity_val = evaluate(valid_dataloader, model, criterion)\n",
    "    scheduler.step()\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} \"\n",
    "        \"| time: {:5.2f}s \"\n",
    "        \"| valid perplexity {:8.3f} \"\n",
    "        \"| valid loss {:8.3f}\".format(\n",
    "            epoch,\n",
    "            time.time() - epoch_start_time,\n",
    "            perplexity_val,\n",
    "            loss_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)\n",
    "\n",
    "print(\"Checking the results of test dataset.\")\n",
    "loss_test, perplexity_test = evaluate(test_dataloader, model, criterion)\n",
    "print(\"test perplexity {:8.3f} | test loss {:8.3f} \".format(perplexity_test, loss_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf46e00",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "- What is wrong with this implementation?\n",
    "- Preprocess! ... Or Normalize Correctly!\n",
    "- My batches are sentences, and a sentence might give rise to many (x, y) pairs.\n",
    "- Each sentence - batch has 16 sentences.\n",
    "- I.e. if I have batch 1 maybe it gives rise to 200 (x, y) pairs and another gives rise to 100 (x, y) pairs.\n",
    "- Assume the sum of the cross-etropy is $L_1$ for the first batch and $L_2$ for the second batch.\n",
    "- If I have two batches, one of size 200 and another of size 100, I get ($L_1$/200 + $L_2$/100) / 2 != ($L_1$ + $L_2$)(200 + 100)\n",
    "- Can you fix this?\n",
    "- HW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e20c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
